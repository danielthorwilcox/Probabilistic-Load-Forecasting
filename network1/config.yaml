parameters:
  batch_size: 64
  dropout: 0.2
  hidden_dim: 4
  layer_dim: 3
  learning_rate: 0.003
  n_epochs: 50
  pred_period: 24
  train_period: 168
  weight_decay: 1.0e-06
